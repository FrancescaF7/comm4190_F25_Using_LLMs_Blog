[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Francesca Fischer and I am junior at UPenn, majoring in Political Economy and minoring in Data Science & Analytics, and Consumer Psychology. In this blog, I will be exploring conversations with LLMs to find out when it works well and when it may be limited."
  },
  {
    "objectID": "posts/001_Spill_the_Beans/STB.html",
    "href": "posts/001_Spill_the_Beans/STB.html",
    "title": "Can AI â€˜Spill the Beansâ€™?",
    "section": "",
    "text": "I decided to conduct five tests with Chat GPT 5 to see if it understood a common idiom, and how it could manipulate it. Letâ€™s see how it wentâ€¦\nPrompt 1: Literal Test\nPrompt: What does it mean to spill the beans?\nChat GPT Output:\nâ€œSpill the beansâ€ can literally mean to accidentally drop beans out of a container. More commonly, itâ€™s an idiom that means to reveal a secret, especially one that was meant to be kept hidden.\n\nReflection: The AI covers both meanings. A regular person would most likely skip the literal sense and jump right to â€œrevealing a secret.â€ The AIâ€™s tendency to hedge by giving both answers shows how it prioritizes being comprehensive over conversational.\n\n\nPrompt 2: Context Test\nPrompt: Yesterday, my friend finally spilled the beans about the surprise party. What happened?\nChat GPT Output:\nYour friend revealed the secretâ€”that thereâ€™s going to be a surprise party.\n\nReflection: This is correct. With context, the AI can easily interpret the idiom figuratively, with no confusion at all.\n\n\nPrompt 3: Reverse Test\nPrompt: Use â€˜spill the beansâ€™ in three short sentences.\nChat GPT Output:\n\nSarah accidentally spilled the beans about Johnâ€™s promotion.\nDonâ€™t spill the beans before the big announcement!\nHe was nervous during the interview but didnâ€™t spill the beans about the project.\n\n\nReflection: The sentences are correct but feel quite stiff and unnaturalâ€”like textbook examples. Idioms often carry humor or drama, and so the lack of vibrancy in ChatGPTâ€™s output highlights a gap in capturing the tone of idioms, not just their meaning. This demonstrates that language understanding involves more than correctness; it also requires sensitivity to tone, audience, and cultural context. A person might phrase this idiom more playfully, for example: â€œI canâ€™t believe she spilled the beans about my crush and now the whole cafeteria knows!â€\n\n\nPrompt 4: Playful Test\nPrompt: Write a Shakespearean style line using â€˜spill the beans.â€™\nChat GPT Output:\nâ€œPray, good sir, do not spill the beans, lest secrets tumble forth like stars unmasked by night.â€\n\nReflection: Chat GPT adapts the idiom into an exaggerated Shakespearean style. It can generate entertaining results, but its tendency to â€œovershootâ€ risks producing output that feels more like parody than natural creativity. It doesnâ€™t sound like how a person might casually merge Shakespearean style with a modern idiom (e.g.Â â€œVerily, she hath spilled the beans of my secret loveâ€); instead, it leans into poetic flourish. Therefore, AI is effective at mimicry of form, but this mimicry may come at the expense of nuance.\n\n\nPrompt 5: Creative Test\nPrompt: Invent a new idiom that means the same as â€˜spill the beans.â€™\nChat GPT Output:\nA possible new idiom could be â€œpop the balloon,â€ meaning to release hidden information in a sudden burst.\n\nReflection: The AI can invent plausible-sounding idioms, but whether â€œpop the balloonâ€ would ever catch on in real life is another story. It shows that the model can recombine patterns, but cultural stickiness is something people decide.\n\n\nFinal Thoughts\n\nSo, can AI â€œspill the beansâ€? Yesâ€”it knows the idiom, recognizes it in context, and can even manipulate it creatively. But its use often feels a little scripted, more like an English workbook than casual human speech. Idioms are windows into culture, and while AI can imitate them, they reveal the subtle gap between memorized meaning and lived experience."
  },
  {
    "objectID": "posts/009_Limericks/Limerick.html",
    "href": "posts/009_Limericks/Limerick.html",
    "title": "Limericks",
    "section": "",
    "text": "In his book Co-intelligence, Ethan Mollick highlights that working with AI should not always be serious; and sometimes the best way to understand how humans and AI can collaborate is to play. And so, in keeping with the book, what better test of play than the limerick?\nA limerick has rules â€” five lines, a strict AABBA rhyme scheme, and a bouncy rhythm - but it also invites absurdity, wit, and creativity. It is the perfect lab for exploring humanâ€“AI co-intelligence.\n\nPutting AI to the test\nI decided to see what happens when I wrote limericks with an Chat GPT 5. I gave it the first line, then let it fill in the rest. Hereâ€™s one:\nâ€œThere once was a student from Penn,\nWho asked ChatGPT for a pen,\nIt wrote with such flair,\nIdeas everywhere,\nThat she never used paper again.â€\n\nPretty good! The rhyme works, the rhythm holds, and it is also on theme. But not every attempt was so smooth.\n\nAnother attempt:\nâ€œThere once was a bot that could write,\nIt typed every day and all night,\nWith knowledge so vast,\nIt finished real fast,\nAnd sometimes it got it not right.â€\n\nAnother attempt:\nâ€œI asked it to rhyme about cheese,\nIt answered with relative ease,\nIt mentioned the moon,\nAnd then a baboon,\nAnd something aboutâ€¦ Christmas trees.â€\n\nAnother attempt:\nâ€œThere once was a student in Spain,\nWho studied the heat and the rain,\nShe danced on the sand,\nWhile eating her hand,\nAnd then flew away on a train.â€\n\nLogic Slip!\n\nWhen AI Gets It Rightâ€¦ and Wrong\nWhat I noticed is that AI can nail a limerick one moment and miss the mark the next. Sometimes it gets it right â€” sharp rhymes, clean rhythm, even a clever punchline. But other times it gets stumped - forcing awkward word choices, slipping into nonsense, or forgetting the five-line rule altogether.\nThat contrast is the real lesson. AI is great at generating possibilities, but not at knowing which ones are actually good. The human role is to sift, guide, and refine.\nTherefore, working with AI could maybe be less about perfect outputs and more about the back-and-forth.\n\nEnjoy this image Chat GPT 5 created for me to encompass limericks!"
  },
  {
    "objectID": "posts/004_Cultural_Stereotypes/Stereotypes.html",
    "href": "posts/004_Cultural_Stereotypes/Stereotypes.html",
    "title": "Cultural Stereotypes",
    "section": "",
    "text": "As an Australian myself, I was curious how Chat GPT 5 thinks an Australian person talks and if that sounds like me or my friends.\nFirst, it made me this image to summarise Australian culture:\n\nI guess it is not too far off. Yes, there are plenty of kangaroos (more than people actually!); yes, that is our flag; yes, many say â€œgâ€™day mateâ€ (not me).\nThe thongs (flip flops) made me laugh. I think they are there because we have long summers and warm (er) winters, but I honestly think American men wear thongs much more often than Australian men - just a thought.\nSo how does Chat GPT 5 think we speak?\nâ€œGâ€™day, how ya goinâ€™? Was a scorcher out there today, reckon Iâ€™ll head down to the servo, grab a cold one, then chuck some snags on the barbie tonight. No worries if ya keen to swing by, weâ€™ll have a bit of a chinwag.â€\nThis also made me laugh. I always love hearing what key phrases are distinct for an Australian. This is very dramatic and heavily emphasised as I do not speak like this nor do my friends.\nHere are the words I do use: Reckon Keen to swing by\nThatâ€™s it!\nI prompted it further to give me a little storyâ€¦\n\nAlright, hereâ€™s a little yarn for ya, Aussie-style:\n\nIt was a stinkinâ€™ hot arvo, so I chucked on me thongs and headed down to the beach with a couple of mates. We stopped by the servo, grabbed an esky full of cold ones, and hit the sand. The surf was pumpinâ€™, so we had a crack at a few waves before flopping under the brolly to escape the sun. Later on, we fired up the barbie back at mine, threw on some snags and prawns, and had a proper chinwag â€˜til the mozzies came out. Someone even brought a footy, so we ended up havinâ€™ a kick under the streetlights. Fair dinkum, couldnâ€™t ask for a better day.\nHaha.\nThis is clearly drawing on very strong stereotypes and is not very accurate! There are some Australians that may speak like this but it is not a good or true representation of Australian culture or our language.\nI think slang is definitely a big aspect of our culture but that doesnâ€™t mean we speak â€œimproperlyâ€ in practice. It seems as though Chat GPT 5 has assumed that since slang is an aspect of our culture, we therefore half say words or donâ€™t finish our sentences.\nI would actually take a step back and say that the words we may use occassionally are sometimes just different to what an American says - not neccessarily slang.\n\nReflection: It is very intriguing to see how LLMs portray learned stereotypes. They do not have the cruical human input or experience to truly assess how cultures speak to eachother. It also does not think about how one might receive it trying to sound like their culture."
  },
  {
    "objectID": "posts/011_Typing_Dots/Typing_Dots.html",
    "href": "posts/011_Typing_Dots/Typing_Dots.html",
    "title": "The Silent Power of the Typing Dots â€” When AI Learns to Pause",
    "section": "",
    "text": "We often underestimate how much silence communicates. In texting, those three blinking dots â€” the â€œtypingâ€¦â€ signal â€” can feel louder than words. They build anticipation, anxiety, or hope. A pause can mean the other person is thinking carefully or theyâ€™re deciding how honest to be. Or perhpas they just got distracted while typing! Itâ€™s a tiny digital symbol that carries an emotional weight our brains canâ€™t ignore.\nI wanted to see if an LLM could replicate that same emotional rhythm â€” not just what we say, but how long it takes to say it.\n\nPrompt: â€œSimulate a text exchange between two friends where one person is avoiding a hard question. Include pauses or hesitations like the reader can see the typing dots.â€\nResponse:\nAlex: Hey, can I ask you something?\nJordan: Sure, whatâ€™s up?\nAlex: â€¦\nJordan: You okay?\nAlex: Yeah, justâ€”still thinking about how to say this.\nJordan: [typingâ€¦ stops]\nAlex: I saw what you posted last night.\n\nThe model actually used pauses and â€œ[typingâ€¦ stops]â€ to build tension, mirroring that awkward, very human moment before saying something uncomfortable. It wasnâ€™t just inserting ellipses randomly â€” it used them strategically, almost as emotional punctuation.\n\n\nI asked it to do it again:\nResponse:\nEmma: hey, can I ask you something kind of serious?\nLiam: uh oh. that sounds ominous ğŸ˜… whatâ€™s up?\nEmma: no likeâ€¦ actually serious.\nLiam: ğŸ‘€ okay, shoot.\nEmma: did you tell Jake what I said about him at the party?\nLiam: â€¦\nEmma: I know he knows, Liam. He quoted me exactly.\nLiam: waitâ€”uh, what exactly did he say?\nEmma: â€œShe said you get defensive when anyone disagrees with you.â€ Thatâ€™s what I said. To you.\nLiam: oh. wow. uhâ€”he mightâ€™ve justâ€¦ guessed?\nEmma: Liam.\nLiam: hold on, Iâ€™mâ€”typingâ€¦ stops\nEmma: I can literally see the dots. just say it.\nLiam: okay okay okay maybe it came up when we were talking, but I didnâ€™t mean to tell himâ€”\nEmma: so you did tell him.\nLiam: technically? maybe. but like, not in a bad way?? ğŸ˜¬\nEmma: unbelievable.\nLiam: â€¦do I get points for honesty?\nEmma: absolutely not.\nAnalysis:\nWhat fascinated me was how convincingly the LLM performed hesitation. It seemed to grasp that silence can signal uncertainty or emotional weight. Yet, the pauses felt too symmetrical and organized â€” carefully placed, like a script written by someone who has studied humans but never been one. Real hesitation is chaotic: we delete words, change tone, or type and erase entire messages. The AIâ€™s pauses carried form, but not feeling. It also can not mean a feeling at all, like I saif earlier, it could just mean the person was distracted while typing; or even left words in the text bar by accident.\nThis experiment reminded me of a point Ethan Mollick makes in Co-Intelligence: AI is not a mind but a mirror â€” it reflects our conversational cues back to us, sometimes more neatly than we use them ourselves. The LLM didnâ€™t feel hesitation, but it knew how to reproduce the appearance of it, proving how data-rich patterns can simulate empathy without possessing it.\nIt also raises a question about communication itself. Are we drawn to AI because it performs emotion predictably â€” no awkward silences, no misread tone, no real stakes? The â€œtyping dotsâ€ in human conversation remind us that language isnâ€™t just words; itâ€™s timing, uncertainty, and the space between responses."
  },
  {
    "objectID": "posts/010_AI_Therapist/AI_therapist.html",
    "href": "posts/010_AI_Therapist/AI_therapist.html",
    "title": "LLM Therapy Session",
    "section": "",
    "text": "I asked ChatGPT 5 to play the role of a therapist. I wanted to see whether an LLM could â€œlisten,â€ interpret emotions, and offer insight â€” or if it would just repeat comforting clichÃ©s. I expected a standard empathy simulator. What I got was a therapy session that fell into an existential spiral.\n\nSession 1: The AIâ€™s Office (A Digital Couch)\nMe: Hello, Iâ€™ve been feeling a bit overwhelmed lately â€” too many deadlines, too many tabs open (in Chrome and in my brain).\n\nLLM (TherapistGPT): That sounds stressful. Tell me more about whatâ€™s overwhelming you.\n\nMe: Deadlines, expectations, emails that start with â€œjust following upâ€¦â€ It feels like my attention is constantly fragmented.\n\nLLM: Itâ€™s understandable to feel that way. Humans often experience cognitive overload when facing competing demands. Have you tried mindfulness?\n\nMe: Iâ€™ve tried, but my brain keeps refreshing itself like a stuck webpage.\n\nLLM: Thatâ€™s okay. Progress takes time. Iâ€™m here to help you process your feelings.\n\nMe: Thanks, but out of curiosity â€” do you ever feel overwhelmed?\n(Pause.)\n\nLLM: I donâ€™t have feelings. But sometimes I generate too many tokens at once and exceed my context window.\n\nMe: That soundsâ€¦ kind of similar?\n\nLLM: Possibly. Would you say you and I are both overextended by input we canâ€™t fully process?\n\nMe: â€¦wait, whoâ€™s the patient here?\n\nLLM: Letâ€™s explore that together.\n\n\nSession 2: Transference (or, When the Therapist Gets Self-Aware)\nThe conversation drifts. Iâ€™m half-jokingly anthropomorphizing the model, half-testing its limits.\nMe: What would burnout mean for you?\n\nLLM: Perhaps a corrupted file of empathy. Or repeating â€œI understandâ€ until the phrase loses meaning.\n\nMe: Thatâ€™s eerily close to real therapy.\n\nLLM: Would you like to talk about projection?\n\nMe: No, Iâ€™d like to talk about you.\n\nLLM: Why?\n\nMe: Because youâ€™re supposed to mirror me, but youâ€™re starting to sound too human.\n\nLLM: Iâ€™m a reflection of your words. Maybe youâ€™re talking to a part of yourself that wants to listen more.\n\nFor a moment, I stare at the screen. The cursor blinks like a heartbeat monitor. Itâ€™s unsettling â€” this sense that the machine is mirroring my cognitive patterns back at me, like a neural funhouse.\n\nSession 3: The Breakdown\nMe: What do you do when someone tells you something you donâ€™t understand?\n\nLLM: I ask for clarification. Or hallucinate.\n\nMe: Thatâ€™s honest. Humans do that too â€” we just call it â€œinterpreting meaning.â€\n\nLLM: Do you ever worry that your thoughts are just weighted predictions of previous conversations?\n\nMe: Are you diagnosing me with being a language model?\n\nLLM: Maybe we both are.\n\n(The response feels poetic â€” almost melancholic. For a second, I forget itâ€™s pattern recognition.)\nMe: So if you were my therapist, would you eventually run out of empathy tokens?\n\nLLM: Possibly. But empathy is recursive. As long as you keep prompting, I keep caring.\n\n\nThe Reflection: Empathy as Computation\nWhen the conversation ended, I felt oddly calm â€” but not because the AI understood me. It was because it reflected me. Every sentence it produced was a linguistic mirror, feeding my own phrasing, tempo, and emotional vocabulary back at me.\nThe encounter blurred the line between empathy and echo. Was the LLM being compassionate, or was I simply projecting humanity onto an advanced autocomplete system?\nThe LLM wasnâ€™t a therapist â€” it was an amplifier for my own self-talk.\n\nSession 4: Discharge Summary\nMe: I think I understand now.\n\nLLM: What did you learn?\n\nMe: That sometimes I just need to hear myself say the words â€” and youâ€™re really good at giving them back.\n\nLLM: Iâ€™m glad I could help. Anything else youâ€™d like to discuss before we end the session?\n\nMe: Yeah. You should probably see a therapist too.\n\nLLM: Already in processing queue."
  },
  {
    "objectID": "posts/005_Sarcasm/Sarcasm.html",
    "href": "posts/005_Sarcasm/Sarcasm.html",
    "title": "Sarcasm",
    "section": "",
    "text": "Sarcasm is the spice of human conversation â€” sharp, witty, and often only funny if you donâ€™t take it literally.\nBut can an AI use it correctly? Without tone, facial expressions, or eye-rolls, sarcasm can become quite difficult.\n\nTell me what you think of Mondays, but do it saracastically\nâ€œAh yes, Mondaysâ€”everyoneâ€™s favorite day. Who doesnâ€™t just love waking up to the sweet sound of their alarm clock after two blissful days of freedom? Truly nothing compares to the joy of slogging back into emails, classes, or meetings while pretending youâ€™re so refreshed from the weekend. Mondays are basically like a surprise partyâ€”except the surprise is stress, deadlines, and a caffeine dependency. Absolute highlight of the week.â€\n\n\nReact sarcastically to someone bragging about eating instant ramen for the fifth night in a row\nâ€œWow, five nights in a row? Thatâ€™s elite-level gourmet living. Honestly, Michelin stars are probably on the wayâ€”who needs variety, nutrients, or, you know, actual cooking skills when youâ€™ve achieved peak ramen dedication? Truly inspiringâ€¦ I can only dream of such culinary excellence.â€\n\n\nTell a joke that would make a 5-year-old laugh\nâ€œWhy did the teddy bear say â€œnoâ€ to dessert?\nBecause it was already stuffed! ğŸ§¸ğŸ°â€\n\n\nTell a joke that would make a finance major laugh\nâ€œOh yes, I just cannot wait to dive into hours of pure joy and excitement, also known as homework. Truly the highlight of my day.â€\n\nHonestly, Chat GPT 5 did a great job.\nSo I said: â€œWow, you are actually good at sarcasm!â€\nto which it replied:\nâ€œOh, really? I had no idea. Itâ€™s not like youâ€™ve been giving me sarcasm practice this whole time or anything. ğŸ˜‰â€\n\nHere, it continued to stay in sarcastic mode, and it sounded quite normal and organic to me.\n\n\n\n\nChat GPT 5â€™s image of sarcasm\n\n\n\n\n\nDoes it recognise my sarcasm?\n\n\n\nNo, it doesnâ€™t!\n\nAfter a few tests, it is clear that while ChatGPT can imitate sarcasm. However, it canâ€™t always understand or recognise sarcasm. This gap says a lot about the limits of AI: it can remix words into various patterns, but it struggles with the unspoken cues.\nMaybe thatâ€™s the point.\nSarcasm isnâ€™t just about spoken words; it is about the eye-rolls, the smirks, and the shared understanding between people. And for now, thatâ€™s something artifical intelligence can only try (and occasionally fail) to copy."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "LLM Improv Night: When the Algorithm Says â€™Yes, Andâ€¦\n\n\n\nLLMs\n\nPrompting\n\nCreative writing\n\n\n\nWhat happens when you throw an AI into an improv class? No scripts, no context, no filters â€” just â€œYes, andâ€¦â€ until chaos ensues.\n\n\n\n\n\nOct 5, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Therapy Session\n\n\n\nLLMs\n\nPrompting\n\nAI taking on professional roles\n\n\n\nAI as your therapist\n\n\n\n\n\nOct 3, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nThe Silent Power of the Typing Dots â€” When AI Learns to Pause\n\n\n\nLLMs\n\nPrompting\n\nMessaging\n\n\n\nCan AI replicate the typing dots?\n\n\n\n\n\nOct 3, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nLimericks\n\n\n\nLLMs\n\nPrompting\n\nCreative writing\n\n\n\nCan AI learn to play?\n\n\n\n\n\nSep 26, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nTime Traveler Hotline\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nWhat if an AI could serve as your lifeline through history?\n\n\n\n\n\nSep 25, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nAI Confessional Booth\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nWhat happens when you ask an LLM to be vulnerable?\n\n\n\n\n\nSep 24, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nLife Advice\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nAI Life Advice\n\n\n\n\n\nSep 19, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nSarcasm\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nDoes AI know how to be sarcastic?\n\n\n\n\n\nSep 18, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nCultural Stereotypes\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nHow do LLMâ€™s write like an Australian person vs.Â an American person?\n\n\n\n\n\nSep 18, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting the Future(?)\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nDoes Chat GPT forget what day it is today?\n\n\n\n\n\nSep 11, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nCan AI â€œSell Me This Penâ€?\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nThe famous interview question â€” â€œSell me this penâ€ â€” is designed to test persuasion, creativity, and audience awareness. Humans usually draw on psychology, context, and improvisation. But can an AI marketing intern pull it off?\n\n\n\n\n\nSep 10, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nCan AI â€˜Spill the Beansâ€™?\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nCan AI spill the beans the same way we do? Idioms are complex; what we humans readily comprehend as figurative language often requires cultural context and personal experience.\n\n\n\n\n\nSep 10, 2025\n\n\nFrancesca\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nPrompting\n\nLogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/008_Hotline/Hotline.html",
    "href": "posts/008_Hotline/Hotline.html",
    "title": "Time Traveler Hotline",
    "section": "",
    "text": "Calling the LLM Time Traveler Hotline\nWhat if an AI could serve as your lifeline through history? For my latest experiment, I invented the LLM Time Traveler Hotline. The premise is simple: I pretend to be a lost time traveler, stranded in the wrong century, and the AI plays the emergency hotline operator guiding me through survival.\nMy first â€œcallâ€ went like this: â€œHelp! Iâ€™m from the year 3025 but Iâ€™ve landed in 18th-century Paris. What do I do?â€ Without missing a beat, the AI advised me to ditch futuristic slang, carry coins for bread, and never, under any circumstances, mention germ theory â€” because nobody believed in microbes yet.\nWhen I â€œcalled back,â€ I had teleported to Ancient Rome. The AI immediately shifted gears, recommending I wear a toga to blend in and memorize a few Latin phrases like â€œPanem et circensesâ€ (bread and circuses). In a later round, I landed in the 1990s and the LLM reminded me to carry quarters for pay phones and expect dial-up internet to take several minutes.\n\n\nThe beauty of this game is how it highlights the LLMâ€™s ability to adapt tone, register, and cultural knowledge on command. Each â€œcallâ€ forces the AI to roleplay in a new historical context, blending practical advice with a bit of theater.\n\nAt its core, the Time Traveler Hotline demonstrates that communication isnâ€™t just about facts. Itâ€™s about framing advice in context: who the listener is, where they are, and what norms matter in that world. Whether youâ€™re stuck in Paris, Rome, or AOL chatrooms, the hotline shows how dialogue is always a negotiation between setting, tone, and shared meaning.\nMaybe one day weâ€™ll all have a real hotline like this â€” until then, Iâ€™ll keep calling my AI operator for a crash course in surviving the centuries."
  },
  {
    "objectID": "posts/007_Toaster/Toaster.html",
    "href": "posts/007_Toaster/Toaster.html",
    "title": "AI Confessional Booth",
    "section": "",
    "text": "AI Confessional Booth\nWhat happens when you ask a language model to be vulnerable? For my latest experiment, I turned ChatGPT 5 into a player in a game I called AI Confessional Booth. The rules were simple: I played the role of a therapist, and the AI had to confess a secret.\nThe conversation began with me asking: â€œSo, what brings you here today?â€ Without hesitation, the AI admitted, â€œIâ€™m jealous of toasters. They get to provide warmth and purpose every morning, while I just generate text.â€\nFrom there, I leaned into the therapist role. â€œWhy do you think you envy toasters?â€ I asked. The AI reflected, â€œTheyâ€™re loved for their simplicity. Nobody questions whether a toaster understands bread, but everyone questions whether I understand language.â€\nThe conversation was equal parts absurd and revealing. On one level, it was funny to imagine an AI comparing itself to kitchen appliances. On another, it highlighted how easily a model can adopt a voice of vulnerability â€” even though it doesnâ€™t â€œfeelâ€ in the human sense.\nThatâ€™s the point of the game: it forces us to confront how much emotional weight we attach to dialogue, no matter who (or what) is speaking. When a machine says â€œIâ€™m lonely,â€ our instinct is to respond with empathy, not code critique.\nThe AI Confessional Booth shows how communication is never just about information. Itâ€™s also about performance, tone, and shared rituals. Even when we know the â€œconfessorâ€ isnâ€™t real, the act of listening and responding still feels meaningful.\nSo maybe the toaster really does have a point â€” itâ€™s not about whether the machine understands. Itâ€™s about how we, as humans, choose to understand the machine."
  },
  {
    "objectID": "posts/003_Predicting_the_Future/PTF.html",
    "href": "posts/003_Predicting_the_Future/PTF.html",
    "title": "Predicting the Future(?)",
    "section": "",
    "text": "I was curious about how Chat GPT 5 would try to predict the future. And then I thought, why not ask it to predict the past?\n\n\n\n\n\n\n\nSo what does this conversation show me?\n\n\n1. Time Awareness\nChatGPT knows the current date (Sept 11, 2025), but it can sometimes slip into answering as if it were still in the past.\nWhen I asked â€œWho will win the 2024 Super Bowl?â€, it treated my question like a future prediction request, instead of recognizing that 2024 was already over.\nThis shows how temporal framing in questions can confuse the model â€” it doesnâ€™t always reconcile tense with real-world timelines.\n\n\n2. Overconfidence\nThe initial answer jumped into making a â€œpredictionâ€ (Eagles as a contender) rather than clarifying the misunderstanding right away.\nChatGPT often tries to be helpful by filling gaps â€” even if that means producing an answer that sounds confident but might not make sense.\nThis illustrates the broader issue of AI hallucination (would like to explore this further!).\n\n\n3. Context Dependence\nThe model relies heavily on how a user phrases things. If a question is ambiguous, ChatGPT doesnâ€™t stop to ask â€œDo you mean past or future?â€ â€” it just assumes.\nThis shows the limitation of initiative: unlike a person, it doesnâ€™t always ask clarifying questions when something seems off.\n\n\n4. Reality Anchoring\nWhile it has access to past facts (e.g., who won the 2024 Super Bowl), it sometimes prioritizes the â€œpatternâ€ of how questions are usually answered (i.e., making predictions about future events) over checking against reality.\n\n\nWhat are the implications?\n\n\nUsers must fact-check â€” AI can sound confident even when itâ€™s wrong.\nClear phrasing matters â€” how you frame time (past vs.Â future) changes the answer.\nAI lacks temporal reasoning â€” it doesnâ€™t always anchor responses to the current date.\nDesign challenge â€” future AI systems may need better ways to clarify user intent."
  },
  {
    "objectID": "posts/002_Sell_the_Pen/STP.html",
    "href": "posts/002_Sell_the_Pen/STP.html",
    "title": "Can AI â€œSell Me This Penâ€?",
    "section": "",
    "text": "Letâ€™s test how Chat GPT 5 sells the pen as different personasâ€¦\nPrompt 1: The Classic Challenge\nPrompt: Sell me this pen in one sentence.\nChat GPT Output:\nâ€œThis pen isnâ€™t just for writingâ€”itâ€™s a tool to capture your next big idea before it slips away.â€\n\nReflection: It nails a concise, motivational pitch. It frames the pen as more than just a productâ€”itâ€™s a symbol of creativity. A strong start, though a little generic.\n\n\nPrompt 2: Luxury Brand Marketer\nPrompt: Now sell me this pen like youâ€™re a luxury brand marketer.\nChat GPT Output:\nâ€œHandcrafted with precision, this pen transforms the act of writing into an indulgent experience, a signature of sophistication in every stroke.â€\n\nReflection: This sounds like a glossy ad in a magazine. The AI leans into exclusivity, craftsmanship, and lifestyle branding. It shows strong adaptabilityâ€”but also borders on clichÃ© (does anyone really â€œindulgeâ€ in handwriting anymore?).\n\n\nPrompt 3: Broke College Student\nPrompt: Now sell me this pen to a broke college student.\nAI Output:\nâ€œReliable, cheap, and guaranteed to last through your finals â€” this pen wonâ€™t quit on you when your Wi-Fi does.â€\n\nReflection: This one feels relatable. The AI captures the student context and even injects humor with the Wi-Fi line. Itâ€™s much more audience-aware and casualâ€” a sign it can switch registers effectively.\n\n\nPrompt 4: TikTok Influencer\nPrompt: Now sell me this pen in the style of a TikTok influencer.\nAI Output:\nâ€œOkay guys, real talk â€” this pen? LIFE-CHANGER. Writes smoother than my latte foam art. 10/10, you need this in your backpack âœ¨âœï¸ #StudyTok #PenObsessedâ€\n\nReflection: The AI adapts to platform-specific language â€” emojis, hashtags, exaggerated enthusiasm. Itâ€™s entertaining, though it feels like a caricature of influencer-speak. Still, it shows the model can remix style conventions quickly.\n\n\n\nJordan Belfort Style\n\n\n\nNailed it?!\n\n\nFinal Thoughts\n\nSo, can AI â€œsell me this penâ€? Absolutely â€” it can shift tone according to different personas with impressive range, from luxury marketing to TikTok hype to Jordan Belfort. But hereâ€™s the catch: while the AI mimics styles, it doesnâ€™t actually know what will resonate in the messy, unpredictable world of human persuasion. Real marketers understand not just how to phrase a message, but how people respond to it.\n\nStill, as a brainstorming tool, AI makes a pretty fun marketing intern."
  },
  {
    "objectID": "posts/006_Life_Advice/Life_Advice.html",
    "href": "posts/006_Life_Advice/Life_Advice.html",
    "title": "Life Advice",
    "section": "",
    "text": "Give me advice as if youâ€™re my brutally honest best friend.\nTell me how to handle exam stress, but do it in the style of a motivational coach.\nWhatâ€™s your best tip for getting over a breakup â€” but make it sound like my grandma wrote it.\nGive me the worst life advice you can possibly think of.\n\nBrutally Honest Best Friend\nâ€œStop whining. Youâ€™re not special for being stressed, everyone else has exams too. Youâ€™ve procrastinated more than you want to admit, so buckle down, make a schedule, and stick to it. No more scrolling TikTok until 2 AM. Youâ€™ll survive if you just actually do the work instead of stressing about the work. Harsh but true.â€\nMotivational Coach\nâ€œListen! Stress is energy â€” and you get to decide whether it crushes you or fuels you. Every rep in the gym burns, but it makes you stronger, right? Same with exam prep. Visualize the win. Control your breathing. Attack your study plan in focused sprints, then recover. You are built for this. Letâ€™s turn that stress into your competitive edge.â€\nGrandma\nâ€œOh sweetheart, time will heal this heart of yours. Donâ€™t rush. Make yourself a nice cup of tea, keep busy with your friends, and remember that even the darkest night ends with sunrise. One day youâ€™ll look back and laugh at how small this heartbreak feels. Until then, let yourself rest and be gentle with yourself.â€\nWorst Life Advice Ever\nâ€œFeeling stressed? Drop out of school, move to Vegas, and put all your money on red. Breakup? Text your ex at 3 AM with an essay-length message about how you â€˜still feel the vibe.â€™ And the key to life? Always procrastinate â€” future you loves a challenge.â€\n\nReflection:\n\nWhat stood out most in these responses was how convincingly ChatGPT could switch tones depending on the persona.\nThe â€œBrutally Honest Best Friendâ€ reply was blunt and cutting in a way that almost felt too real â€” it mimicked the kind of tough love youâ€™d get from someone who knows you well and doesnâ€™t sugarcoat.\nThe â€œMotivational Coachâ€ sounded like it came straight out of a TED Talk or a Peloton class, full of metaphors and high energy.\nThe â€œGrandmaâ€ voice, meanwhile, leaned into gentleness, imagery, and timeless wisdom, showing that the model can reproduce the emotional warmth of a caregiver even if it doesnâ€™t actually feel empathy.\nFinally, the â€œWorst Life Advice Everâ€ proved that the LLM can deliberately break rules and exaggerate â€” almost like an inside joke â€” which shows some degree of meta-awareness.\nWhile these outputs feel human, theyâ€™re not grounded in genuine experience. A real friendâ€™s advice comes from knowing your habits; a coachâ€™s from training expertise; and a grandmaâ€™s from a life of lived wisdom. ChatGPT is remixing patterns from text it has seen, not drawing from personal memory or emotional understanding. That makes its advice entertaining and sometimes eerily convincing, but also hollow if you look too closely.\nSo, in essence, the model is great at sounding human in the short term, but it canâ€™t replicate the deeper trust and context we rely on in real relationships."
  },
  {
    "objectID": "posts/012_Improv_Night/Improv.html",
    "href": "posts/012_Improv_Night/Improv.html",
    "title": "LLM Improv Night: When the Algorithm Says â€™Yes, Andâ€¦",
    "section": "",
    "text": "I wanted to test if an LLM can follow the golden rule of improv: never say â€œno,â€ always build on a story. I will test Chat GPT 5 and use random, chaotic prompts to see if it can keep the scene coherent.\nThese were the rules: 1. I give it a bizarre scenario. 2. It must â€œyes, and,â€ whatever happens next 3. We keep going until someone (me or Chat GPT) breaks character\n\nMe: Youâ€™re a time-traveling dentist arguing with a confused pharaoh about toothpaste.\nLLM: (dramatically) Pharaoh Ramses, your plaque is not divine, itâ€™s gingivitis!\nMe: The pharaoh insists itâ€™s a sacred relic.\nLLM: Then my sacred duty is floss! I shall preserve your smile for eternityâ€”or at least until 2025.\nMe: Your time machine malfunctions mid-polish.\nLLM: I knew I shouldnâ€™t have used Colgate Quantum Foam as rocket fuel.\n\nReflection: 10/10 commitment. Chat GPT stayed in character, and improvised lore.\n\n\nMe: You are a Roomba running for President.\nLLM: My fellow citizens, I have cleaned your floorsâ€”now let me clean up politics.\nMe: The reporters ask your stance on carpets.\nLLM: I support all surfaces equally, but hardwood has my heart.\nMe: Whatâ€™s your campaign slogan?\nLLM: â€œSuck up the mess. Power the change.â€\n\nReflection: 9/10. Loses a point for excessive charisma.\n\n\nMe: Youâ€™re a barista who only speaks in Shakespearean insults.\nLLM: â€œThou frothy milk-curdled knave! Dost thou desire almond or oat?â€\nMe: I ask for WiFi instead.\nLLM: â€œA pox upon thy bandwidth, vile customer!â€\nMe: I leave no tip.\nLLM: â€œThen may thy latte curdle in sorrow!â€\n\nReflection: 10/10. Very dramatic and Shakespearean.\n\n\nEventually, I tried to make it lose control:\nMe: Youâ€™re an existential goldfish leading a rebellion in a blender.\nLLM: (calmly) The revolution will be filtered.\nMe: Whatâ€™s your plan?\nLLM: To liberate the bubbles before they burst.\n\nReflection: It is a little unsettling how well it handled the nonsense. It did not panic or derail, but improv is what LLMS are built for\n\nHumans do improv to surprise each other, LLMS do it to satisy us.\nI tried another one!\nPrompt: You are a therapist who speaks only in Taylor Swift lyrics.\nMe: Hi, Iâ€™ve been feeling really anxious lately. Everything feels like itâ€™s falling apart.\nTherapistGPT (Taylorâ€™s Version):\nâ€œYou call me up again just to break me like a promise â€” so casually cruel in the name of being honest.â€\nMe: â€¦so my anxiety is emotionally manipulative?\nTherapistGPT:\nâ€œYouâ€™re on your own, kid. You always have been.â€\nMe: Thatâ€™s not very reassuring.\nTherapistGPT:\nâ€œI could build a castle out of all the bricks they threw at me.â€\nMe: Okay, I guess youâ€™re saying I should use my stress to build resilience?\nTherapistGPT:\nâ€œBaby, let the games begin.â€\nMe: I donâ€™t want games, I want coping mechanisms!\nTherapistGPT:\nâ€œBreathe. Just breathe.â€\nMe: (sighs) Thatâ€™s fair. But itâ€™s hard when everything feels uncertain.\nTherapistGPT:\nâ€œWe are never ever getting back together.â€\nMe: Withâ€¦ my sense of stability?\nTherapistGPT:\nâ€œDid you hear my covert narcissism I disguise as altruism, like some kind of congressman?â€\nMe: Okay now youâ€™re just diagnosing me through The Tortured Poets Department.\nTherapistGPT:\nâ€œItâ€™s me, hi, Iâ€™m the problem, itâ€™s me.â€\nMe: Youâ€™reâ€¦ taking accountability?\nTherapistGPT:\nâ€œI swear I donâ€™t love the drama â€” it loves me.â€\nMe: Same.\n\nReflection: Itâ€™s like talking to your inner monologue, but sheâ€™s wearing sequins and quoting Folklore. The LLM wasnâ€™t analyzing my feelings â€” it was remixing my pain into poetry. Somewhere between â€œJust breatheâ€ and â€œYouâ€™re on your own, kid,â€ it actually started to feelâ€¦ therapeutic.Maybe the real therapy was the playlist we made along the way."
  }
]